---
title: "NN heure de la journée"
author: "Francis Duval"
date: "2022-12-15"
output: html_document
---

```{r setup, include = F}
knitr::opts_chunk$set(echo = T)
library(keras)
library(tidymodels)
library(targets)
library(tensorflow)
library(glue)
library(tidyverse)
theme_set(theme_bw())
```

# Importer et visualiser le jeu de données

```{r}
nn_data_time_of_day <- tar_read(nn_data_time_of_day)
```

```{r}
names(nn_data_time_of_day)
```

Chaque véhicule possède 96 inputs (x_1 à x_96) et une variable réponse (claim_ind_cov_1_2_3_4_5_6). On a divisé la journée en 96 périodes de 15 minutes (0:00 à 0:15, 0:15 à 0:30, 0:30 à 0:45, etc.). Les inputs correspondent à la proportion de conduite (en minutes) faite dans la période de 15 minutes. Par exemple, pour le véhicule 1, la proportion de conduite de 0:00 à 0:15 est de `r nn_data_time_of_day$x_1[1]`. 

```{r}
nn_data_time_of_day$x_1[1]
```

C'est donc un jeu de données qui donne la distribution de conduite dans une journée typique pour chaque véhicule. La journée typique du véhicule 1 ressemble à ceci:

```{r}
nn_data_time_of_day[1, ] %>% 
  summarise_at(vars(x_1:x_96), mean) %>% 
  pivot_longer(cols = everything()) %>% 
  mutate(name = as.numeric(str_sub(name, 3))) %>% 
  ggplot(aes(x = name, y = value)) +
  geom_col() +
  xlab("# période de 15 minutes") +
  ylab("Proportion de la conduite")
```

La journée typique de tous les véhicules confondus ressemble à ceci:

```{r}
nn_data_time_of_day %>% 
  summarise_at(vars(x_1:x_96), mean) %>% 
  pivot_longer(cols = everything()) %>% 
  mutate(name = as.numeric(str_sub(name, 3))) %>% 
  ggplot(aes(x = name, y = value)) +
  geom_col() +
  xlab("# période de 15 minutes") +
  ylab("Proportion de la conduite")
```

# Modélisation

On va essayer de prédire les réclamations avec seulement cette information.

## Séparation en entrainement et test

```{r}
set.seed(1994)
split <- initial_split(nn_data_time_of_day, strata = claim_ind_cov_1_2_3_4_5_6)

train <- training(split)
test <- testing(split)

train_y <- to_categorical(train$claim_ind_cov_1_2_3_4_5_6)
test_y <- to_categorical(test$claim_ind_cov_1_2_3_4_5_6)

train_x <- as.matrix(select(train, -vin, -claim_ind_cov_1_2_3_4_5_6))
test_x <- as.matrix(select(test, -vin, -claim_ind_cov_1_2_3_4_5_6))
```

# GLM

```{r}
glm_fit <- glm(claim_ind_cov_1_2_3_4_5_6 ~ x_1:x_96, family = binomial, data = train)
glm_pred_test <- predict(glm_fit, type = "response", newdata = test)
roc_auc_vec(test$claim_ind_cov_1_2_3_4_5_6, 1 - glm_pred_test) %>% round(4)
```

## GLMNET

```{r}
folds <- vfold_cv(train, v = 5, strata = claim_ind_cov_1_2_3_4_5_6)

glmnet_spec <- 
  logistic_reg(
    penalty = tune(),
    mixture = tune()
  ) %>%
    set_engine("glmnet")

grid <- grid_regular(penalty(), mixture(), levels = c(mixture = 5, penalty = 15))

rec <- 
  recipe(claim_ind_cov_1_2_3_4_5_6 ~ ., data = train) %>%
  update_role(vin, new_role = "ID") %>%
  step_normalize(all_numeric(), -all_outcomes())

wf <- 
  workflow() %>% 
  add_model(glmnet_spec) %>% 
  add_recipe(rec)
```

```{r}
set.seed(1994)
tuning <- 
 tune_grid(
   wf,
   resamples = folds,
   grid = grid
 )
```

```{r}
highest_auc <- select_best(tuning, "roc_auc")
final_glmnet <- finalize_workflow(wf, highest_auc)
```

```{r}
glmnet_fit <- fit(final_glmnet, train) 
```

```{r}
glmnet_pred_test <- predict(glmnet_fit, new_data = test, type = "prob")
roc_auc_vec(test$claim_ind_cov_1_2_3_4_5_6, glmnet_pred_test$.pred_0) %>% round(4)
```

## Réseau de neurones

```{r}
network <- 
  keras_model_sequential() %>% 
  layer_dense(units = 256, activation = "relu", input_shape = ncol(train_x)) %>% 
  layer_dense(units = 128, activation = "relu") %>%
  layer_dense(units = 2, activation = "softmax")

network %>% 
  compile(
    optimizer = "adam",
    loss = "categorical_crossentropy",
    metrics = "accuracy"
  )

history <- network %>% fit(train_x, train_y, epochs = 10, batch_size = 128, validation_split = 0.2)
preds <- predict(network, test_x)

roc_auc_vec(factor(test_y[ , 2]), preds[ , 1]) %>% round(4)
```

Le réseau de neurones (AUC = `r roc_auc_vec(factor(test_y[ , 2]), preds[ , 1]) %>% round(4)`) donne une AUC légèrement inférieure au GLMNET ((AUC = `r roc_auc_vec(test$claim_ind_cov_1_2_3_4_5_6, glmnet_pred_test$.pred_0) %>% round(4)`)), mais supérieure au GLM (AUC = `r roc_auc_vec(test$claim_ind_cov_1_2_3_4_5_6, 1 - glm_pred_test) %>% round(4)`). Cependant, l'architecture utilisée est très simple et on n'a pas fait de régularisation. La performance pourrait donc facilement être améliorée. Le réseau de neurones est également beaucoup moins long à entrainer que le GLMNET.
